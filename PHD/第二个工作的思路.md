我的框架是：提出一个轻量化的基于4F系统的optical encoder+digital encoder，利用知识蒸馏对整个框架进行训练，将核心特征latent code 编码到optical encoder上(光学掩码）(关于这点我认为是有误的？因为我只能最多做到把latent code和optical encoder的结果对齐）。

在训练过程中采用多任务头正则化手段，学习一个通用的shared optical encoder。
针对光学数据和仿真数据之间的差异，不再使用微调解决。
考虑采用虚假相关性思路解决数据分布差异。

这是我原来的想法，我重新思考了一下，我没有明确提出我为什么要在optical encoder 后面引入类似e2style的digital encoder 的原因，我一开始的想法是希望这个digital encoder能够 将光学输出对齐到latent space ，最好能够让optical mask变得像latent space 一样具有语义信息，这样部署到边缘设备上就不用存储百万像素，只要通过我的4F设备获得有语义的设备即可，从而节省大量存储空间，此外，4F具有高速高带宽的特点，因此让它在自动驾驶等边缘领域执行操作也很好，如果这时候有latent space 作为辅助 那会更好。

此外，我希望这个optical encoder 能够有足够的泛化性，就是说这个optical encoder出来的feature 能够用到各个任务头，这就足以证明它具有一定的语义信息了对吧。
另外，这个digital encoder 也可以作为optical encoder的一个非线性处理使用。
我认为，latent space和多任务训练的方案某种程度上是相互的，都能够体现optical encoder 是一个足够shared的encoder.。

但是 我遇到了一个问题，真实的光学系统在做推理的时候，可能会和仿真就是训练时候会有比较大的差距，我首先分析了这个问题的来源 我认为这是一个跨域、虚假相关性的问题。
关于这个问题，我查询了很多资料，我发现这个问题大多数人其实不怎么关注，一般都是采用微调的操作进行处理。
还有一些就是会用大量的真实数据参与训练解决，但是真实场景下的数据往往比较昂贵，因此就要考虑怎么对图像很好的仿真来处理。

我首先思考的是用虚假相关性用invariantlearing解决这个问题，这种方法往往需要两个域一起参与训练，但是real域的数据比较稀少。
所以我查询了一些小样本学习和跨域结合的文献，Meta-FDMixup: Cross-Domain Few-Shot Learning Guided by Labeled Target Data我希望这篇文章能为我解决，但是我发现这些方法都会使我的网络结构更加复杂，本着奥卡姆剃刀的原则，我把重心转移到了 latent space上面 就是如果在real 场景下 我的latent space 生成的latent code不太会受到真实场景下光照噪声 传感器噪声以及激光衍射等问题的影响，即latent code 的分布仍然基于在原来的feature上 那么我的网络应该是有泛化性的。
于是我的重心，又转移到了思考如何让类似psp、e4e以及e2style的encoder总是能够采样到正确的latent code
